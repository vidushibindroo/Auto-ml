{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(df, test_size):\n",
    "    \n",
    "    if isinstance(test_size, float):\n",
    "        test_size = round(test_size * len(df))\n",
    "\n",
    "    indices = df.index.tolist()\n",
    "    test_indices = random.sample(population=indices, k=test_size)\n",
    "\n",
    "    test_df = df.loc[test_indices]\n",
    "    train_df = df.drop(test_indices)\n",
    "    \n",
    "    return train_df, test_df\n",
    "\n",
    "\n",
    "def generate_data(n, specific_outliers=[], n_random_outliers=None):\n",
    "    \n",
    "    # create data\n",
    "    data = np.random.random(size=(n, 2)) * 10\n",
    "    data = data.round(decimals=1)\n",
    "    df = pd.DataFrame(data, columns=[\"x\", \"y\"])\n",
    "    df[\"label\"] = df.x <= 5\n",
    "\n",
    "    # add specific outlier data points\n",
    "    for outlier_coordinates in specific_outliers:\n",
    "        df = df.append({\"x\": outlier_coordinates[0],\n",
    "                        \"y\": outlier_coordinates[1],\n",
    "                        \"label\": True}, \n",
    "                       ignore_index=True)\n",
    "\n",
    "    ## add random outlier data points\n",
    "    if n_random_outliers:\n",
    "        outlier_x_values =  (6 - 5) * np.random.random(size=n_random_outliers) + 5  # value between 5 and 6\n",
    "        outlier_y_values = np.random.random(size=n_random_outliers) * 10\n",
    "\n",
    "        df_outliers = pd.DataFrame({\"x\": outlier_x_values.round(decimals=2),\n",
    "                                    \"y\": outlier_y_values.round(decimals=2),\n",
    "                                    \"label\": [True] * n_random_outliers})\n",
    "\n",
    "        df = df.append(df_outliers, ignore_index=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def plot_decision_boundaries(tree, x_min, x_max, y_min, y_max):\n",
    "    color_keys = {True: \"orange\", False: \"blue\"}\n",
    "    \n",
    "    # recursive part\n",
    "    if isinstance(tree, dict):\n",
    "        question = list(tree.keys())[0]\n",
    "        yes_answer, no_answer = tree[question]\n",
    "        feature, _, value = question.split()\n",
    "    \n",
    "        if feature == \"x\":\n",
    "            plot_decision_boundaries(yes_answer, x_min, float(value), y_min, y_max)\n",
    "            plot_decision_boundaries(no_answer, float(value), x_max, y_min, y_max)\n",
    "        else:\n",
    "            plot_decision_boundaries(yes_answer, x_min, x_max, y_min, float(value))\n",
    "            plot_decision_boundaries(no_answer, x_min, x_max, float(value), y_max)\n",
    "        \n",
    "    # \"tree\" is a leaf\n",
    "    else:\n",
    "        plt.fill_between(x=[x_min, x_max], y1=y_min, y2=y_max, alpha=0.2, color=color_keys[tree])\n",
    "    \n",
    "    return\n",
    "\n",
    "\n",
    "def create_plot(df, tree=None, title=None):\n",
    "    \n",
    "    sns.lmplot(data=df, x=\"x\", y=\"y\", hue=\"label\", \n",
    "               fit_reg=False, height=4, aspect=1.5, legend=False)\n",
    "    plt.title(title)\n",
    "    \n",
    "    if tree or tree == False: # root of the tree might just be a leave with \"False\"\n",
    "        x_min, x_max = round(df.x.min()), round(df.x.max())\n",
    "        y_min, y_max = round(df.y.min()), round(df.y.max())\n",
    "\n",
    "        plot_decision_boundaries(tree, x_min, x_max, y_min, y_max)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Decision Tree helper functions\n",
    "# 1.1 Data pure?\n",
    "def check_purity(data):\n",
    "    \n",
    "    label_column = data[:, -1]\n",
    "    unique_classes = np.unique(label_column)\n",
    "\n",
    "    if len(unique_classes) == 1:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "    \n",
    "# 1.2 Create Leaf\n",
    "def create_leaf(data, ml_task):\n",
    "    \n",
    "    label_column = data[:, -1]\n",
    "    if ml_task == \"regression\":\n",
    "        leaf = np.mean(label_column)\n",
    "        \n",
    "    # classfication    \n",
    "    else:\n",
    "        unique_classes, counts_unique_classes = np.unique(label_column, return_counts=True)\n",
    "        index = counts_unique_classes.argmax()\n",
    "        leaf = unique_classes[index]\n",
    "    \n",
    "    return leaf\n",
    "\n",
    "\n",
    "# 1.3 Determine potential splits\n",
    "def get_potential_splits(data):\n",
    "    \n",
    "    potential_splits = {}\n",
    "    _, n_columns = data.shape\n",
    "    for column_index in range(n_columns - 1): # excluding the last column which is the label\n",
    "        values = data[:, column_index]\n",
    "        unique_values = np.unique(values)\n",
    "        \n",
    "        potential_splits[column_index] = unique_values\n",
    "    \n",
    "    return potential_splits\n",
    "\n",
    "\n",
    "# 1.4 Determine Best Split\n",
    "def calculate_entropy(data):\n",
    "    \n",
    "    label_column = data[:, -1]\n",
    "    _, counts = np.unique(label_column, return_counts=True)\n",
    "\n",
    "    probabilities = counts / counts.sum()\n",
    "    entropy = sum(probabilities * -np.log2(probabilities))\n",
    "     \n",
    "    return entropy\n",
    "\n",
    "\n",
    "def calculate_mse(data):\n",
    "    actual_values = data[:, -1]\n",
    "    if len(actual_values) == 0:   # empty data\n",
    "        mse = 0\n",
    "        \n",
    "    else:\n",
    "        prediction = np.mean(actual_values)\n",
    "        mse = np.mean((actual_values - prediction) **2)\n",
    "    \n",
    "    return mse\n",
    "\n",
    "\n",
    "def calculate_overall_metric(data_below, data_above, metric_function):\n",
    "    \n",
    "    n = len(data_below) + len(data_above)\n",
    "    p_data_below = len(data_below) / n\n",
    "    p_data_above = len(data_above) / n\n",
    "\n",
    "    overall_metric =  (p_data_below * metric_function(data_below) \n",
    "                     + p_data_above * metric_function(data_above))\n",
    "    \n",
    "    return overall_metric\n",
    "\n",
    "\n",
    "def determine_best_split(data, potential_splits, ml_task):\n",
    "    \n",
    "    first_iteration = True\n",
    "    for column_index in potential_splits:\n",
    "        for value in potential_splits[column_index]:\n",
    "            data_below, data_above = split_data(data, split_column=column_index, split_value=value)\n",
    "            \n",
    "            if ml_task == \"regression\":\n",
    "                current_overall_metric = calculate_overall_metric(data_below, data_above, metric_function=calculate_mse)\n",
    "            \n",
    "            # classification\n",
    "            else:\n",
    "                current_overall_metric = calculate_overall_metric(data_below, data_above, metric_function=calculate_entropy)\n",
    "\n",
    "            if first_iteration or current_overall_metric <= best_overall_metric:\n",
    "                first_iteration = False\n",
    "                \n",
    "                best_overall_metric = current_overall_metric\n",
    "                best_split_column = column_index\n",
    "                best_split_value = value\n",
    "    \n",
    "    return best_split_column, best_split_value\n",
    "\n",
    "\n",
    "# 1.5 Split data\n",
    "def split_data(data, split_column, split_value):\n",
    "    \n",
    "    split_column_values = data[:, split_column]\n",
    "\n",
    "    type_of_feature = FEATURE_TYPES[split_column]\n",
    "    if type_of_feature == \"continuous\":\n",
    "        data_below = data[split_column_values <= split_value]\n",
    "        data_above = data[split_column_values >  split_value]\n",
    "    \n",
    "    # feature is categorical   \n",
    "    else:\n",
    "        data_below = data[split_column_values == split_value]\n",
    "        data_above = data[split_column_values != split_value]\n",
    "    \n",
    "    return data_below, data_above\n",
    "\n",
    "\n",
    "# 2. Decision Tree Algorithm\n",
    "# 2.1 Helper Function\n",
    "def determine_type_of_feature(df):\n",
    "    \n",
    "    feature_types = []\n",
    "    n_unique_values_treshold = 15\n",
    "    for feature in df.columns:\n",
    "        if feature != \"label\":\n",
    "            unique_values = df[feature].unique()\n",
    "            example_value = unique_values[0]\n",
    "\n",
    "            if (isinstance(example_value, str)) or (len(unique_values) <= n_unique_values_treshold):\n",
    "                feature_types.append(\"categorical\")\n",
    "            else:\n",
    "                feature_types.append(\"continuous\")\n",
    "    \n",
    "    return feature_types\n",
    "\n",
    "\n",
    "# 2.2 Algorithm\n",
    "def decision_tree_algorithm(df, ml_task, counter=0, min_samples=2, max_depth=5):\n",
    "    \n",
    "    # data preparations\n",
    "    if counter == 0:\n",
    "        global COLUMN_HEADERS, FEATURE_TYPES\n",
    "        COLUMN_HEADERS = df.columns\n",
    "        FEATURE_TYPES = determine_type_of_feature(df)\n",
    "        data = df.values\n",
    "    else:\n",
    "        data = df           \n",
    "    \n",
    "    \n",
    "    # base cases\n",
    "    if (check_purity(data)) or (len(data) < min_samples) or (counter == max_depth):\n",
    "        leaf = create_leaf(data, ml_task)\n",
    "        return leaf\n",
    "\n",
    "    \n",
    "    # recursive part\n",
    "    else:    \n",
    "        counter += 1\n",
    "\n",
    "        # helper functions \n",
    "        potential_splits = get_potential_splits(data)\n",
    "        split_column, split_value = determine_best_split(data, potential_splits, ml_task)\n",
    "        data_below, data_above = split_data(data, split_column, split_value)\n",
    "        \n",
    "        # check for empty data\n",
    "        if len(data_below) == 0 or len(data_above) == 0:\n",
    "            leaf = create_leaf(data, ml_task)\n",
    "            return leaf\n",
    "        \n",
    "        # determine question\n",
    "        feature_name = COLUMN_HEADERS[split_column]\n",
    "        type_of_feature = FEATURE_TYPES[split_column]\n",
    "        if type_of_feature == \"continuous\":\n",
    "            question = \"{} <= {}\".format(feature_name, split_value)\n",
    "            \n",
    "        # feature is categorical\n",
    "        else:\n",
    "            question = \"{} = {}\".format(feature_name, split_value)\n",
    "        \n",
    "        # instantiate sub-tree\n",
    "        sub_tree = {question: []}\n",
    "        \n",
    "        # find answers (recursion)\n",
    "        yes_answer = decision_tree_algorithm(data_below, ml_task, counter, min_samples, max_depth)\n",
    "        no_answer = decision_tree_algorithm(data_above, ml_task, counter, min_samples, max_depth)\n",
    "        \n",
    "        # If the answers are the same, then there is no point in asking the qestion.\n",
    "        # This could happen when the data is classified even though it is not pure\n",
    "        # yet (min_samples or max_depth base case).\n",
    "        if yes_answer == no_answer:\n",
    "            sub_tree = yes_answer\n",
    "        else:\n",
    "            sub_tree[question].append(yes_answer)\n",
    "            sub_tree[question].append(no_answer)\n",
    "        \n",
    "        return sub_tree\n",
    "\n",
    "\n",
    "# 3. Make predictions\n",
    "# 3.1 One example\n",
    "def predict_example(example, tree):\n",
    "    \n",
    "    # tree is just a root node\n",
    "    if not isinstance(tree, dict):\n",
    "        return tree\n",
    "    \n",
    "    question = list(tree.keys())[0]\n",
    "    feature_name, comparison_operator, value = question.split(\" \")\n",
    "\n",
    "    # ask question\n",
    "    if comparison_operator == \"<=\":\n",
    "        if example[feature_name] <= float(value):\n",
    "            answer = tree[question][0]\n",
    "        else:\n",
    "            answer = tree[question][1]\n",
    "    \n",
    "    # feature is categorical\n",
    "    else:\n",
    "        if str(example[feature_name]) == value:\n",
    "            answer = tree[question][0]\n",
    "        else:\n",
    "            answer = tree[question][1]\n",
    "\n",
    "    # base case\n",
    "    if not isinstance(answer, dict):\n",
    "        return answer\n",
    "    \n",
    "    # recursive part\n",
    "    else:\n",
    "        residual_tree = answer\n",
    "        return predict_example(example, residual_tree)\n",
    "\n",
    "    \n",
    "# 3.2 All examples of a dataframe\n",
    "def make_predictions(df, tree):\n",
    "    \n",
    "    if len(df) != 0:\n",
    "        predictions = df.apply(predict_example, args=(tree,), axis=1)\n",
    "    else:\n",
    "        # \"df.apply()\"\" with empty dataframe returns an empty dataframe,\n",
    "        # but \"predictions\" should be a series instead\n",
    "        predictions = pd.Series()\n",
    "        \n",
    "    return predictions\n",
    "\n",
    "\n",
    "# 3.3 Accuracy\n",
    "def calculate_accuracy(df, tree):\n",
    "    predictions = make_predictions(df, tree)\n",
    "    predictions_correct = predictions == df.label\n",
    "    accuracy = predictions_correct.mean()\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Iris.csv\")\n",
    "df = df.drop(\"Id\", axis=1)\n",
    "df = df.rename(columns={\"species\": \"label\"})\n",
    "X=pd.read_csv(\"Iris.csv\")\n",
    "y=X[\"species\"]\n",
    "X.drop([\"Id\",\"species\"],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Social_Network_Ads.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={\"Purchased\":\"label\"}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(df, test_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>19000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>20000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>43000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>57000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>76000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>395</td>\n",
       "      <td>46</td>\n",
       "      <td>41000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>396</td>\n",
       "      <td>51</td>\n",
       "      <td>23000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>397</td>\n",
       "      <td>50</td>\n",
       "      <td>20000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>398</td>\n",
       "      <td>36</td>\n",
       "      <td>33000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>399</td>\n",
       "      <td>49</td>\n",
       "      <td>36000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>380 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age  EstimatedSalary  label\n",
       "0     19            19000      0\n",
       "1     35            20000      0\n",
       "2     26            43000      0\n",
       "3     27            57000      0\n",
       "4     19            76000      0\n",
       "..   ...              ...    ...\n",
       "395   46            41000      1\n",
       "396   51            23000      1\n",
       "397   50            20000      1\n",
       "398   36            33000      0\n",
       "399   49            36000      1\n",
       "\n",
       "[380 rows x 3 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>94</td>\n",
       "      <td>29</td>\n",
       "      <td>83000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>44</td>\n",
       "      <td>39000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>361</td>\n",
       "      <td>53</td>\n",
       "      <td>34000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>203</td>\n",
       "      <td>41</td>\n",
       "      <td>71000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>30</td>\n",
       "      <td>15000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>41</td>\n",
       "      <td>80000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>393</td>\n",
       "      <td>60</td>\n",
       "      <td>42000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>295</td>\n",
       "      <td>36</td>\n",
       "      <td>63000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>167</td>\n",
       "      <td>35</td>\n",
       "      <td>71000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>356</td>\n",
       "      <td>54</td>\n",
       "      <td>70000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>204</td>\n",
       "      <td>58</td>\n",
       "      <td>101000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>114</td>\n",
       "      <td>42</td>\n",
       "      <td>80000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>143</td>\n",
       "      <td>30</td>\n",
       "      <td>89000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>38</td>\n",
       "      <td>51000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159</td>\n",
       "      <td>32</td>\n",
       "      <td>135000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>235</td>\n",
       "      <td>46</td>\n",
       "      <td>79000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>31</td>\n",
       "      <td>89000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>47</td>\n",
       "      <td>49000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>102</td>\n",
       "      <td>32</td>\n",
       "      <td>86000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>35</td>\n",
       "      <td>44000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age  EstimatedSalary  label\n",
       "94    29            83000      0\n",
       "250   44            39000      0\n",
       "361   53            34000      1\n",
       "203   41            71000      0\n",
       "43    30            15000      0\n",
       "220   41            80000      0\n",
       "393   60            42000      1\n",
       "295   36            63000      0\n",
       "167   35            71000      0\n",
       "356   54            70000      1\n",
       "204   58           101000      1\n",
       "114   42            80000      0\n",
       "143   30            89000      0\n",
       "330   38            51000      0\n",
       "159   32           135000      1\n",
       "235   46            79000      1\n",
       "49    31            89000      0\n",
       "21    47            49000      1\n",
       "102   32            86000      0\n",
       "95    35            44000      0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Age <= 42': [{'EstimatedSalary <= 90000': [0, 1]}, 1]}\n"
     ]
    }
   ],
   "source": [
    "tree = decision_tree_algorithm(train_df, ml_task=\"classification\", max_depth=3)\n",
    "print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = calculate_accuracy(test_df, tree)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree_dic = {\n",
    "    'ml_task':[\"classification\"],\n",
    "    'counter': [0],\n",
    "    'min_samples': [1, 2, 3],\n",
    "    'max_depth': [3, 4, 5, 6]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "class random_search_dtree:\n",
    "    \n",
    "    \"\"\"\n",
    "    Background and Mathematics - \n",
    "    \n",
    "    Class for random search for hyperparameter optimization\n",
    "    \n",
    "    Any distribution which has a finite maxima, the maximum of 60 random obseravtions lie within top 5% of the maximum\n",
    "    with 95% probability.\n",
    "    \n",
    "    \n",
    "    functions - \n",
    "    \n",
    "    1. Constructor (__init__ function)\n",
    "    \n",
    "    Input Arguements - \n",
    "    - estimator -> the model class, should have fit, predict and scoring class - accuracy\n",
    "    \n",
    "    - param_distributions -> dictionary of hyperparamater names as keys and list of values as keys \n",
    "    \n",
    "    - n_iter -> number of iterations random search will run with default value 60\n",
    "    \n",
    "    \n",
    "    2. .fit() method\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, estimator, param_distributions, n_iter = 60):\n",
    "        self.estimator = estimator\n",
    "        self.num_params = len(param_distributions)\n",
    "        param_dist = {}\n",
    "        param_list = []\n",
    "        for param_tupple_ in param_distributions.items(): # convert to numpy array to optimize work\n",
    "            param_dist[param_tupple_[0]] = np.array(param_tupple_[1])\n",
    "            param_list.append(param_tupple_[0])\n",
    "        self.param_dist = param_dist\n",
    "        self.param_list = param_list\n",
    "        self.n_iter = n_iter\n",
    "        \n",
    "        \n",
    "        \n",
    "    def fit(self, train_df, test_df, target_variable = 'label'):\n",
    "        best_params_ = {}\n",
    "        best_score_ = 0\n",
    "        try_params = {}\n",
    "        score = 0\n",
    "        \n",
    "        for i in range(self.n_iter):\n",
    "            for param in self.param_list:\n",
    "                try_params[param] = np.random.choice(self.param_dist[param]) # uses normal distribition\n",
    "                \n",
    "            print(try_params)\n",
    "            # try_params dictionary is ready now\n",
    "            # try:\n",
    "            model = self.estimator(df = train_df,**try_params)\n",
    "            if target_variable != 'label':\n",
    "                train_df.rename(columns={target_variable:\"label\"}, inplace = True)\n",
    "                test_df.rename(columns={target_variable:\"label\"}, inplace = True)\n",
    "            score = calculate_accuracy(test_df, model)\n",
    "            if score > best_score_:\n",
    "                best_score_ = score\n",
    "                best_params_ = try_params.copy()\n",
    "            # except:\n",
    "            #    print('Error in Random Search for Hyperparameter Optimization')\n",
    "                \n",
    "        self.best_params_ = best_params_\n",
    "        self.best_score_ = best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = random_search(decision_tree_algorithm, dtree_dic, n_iter = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ml_task': 'classification', 'counter': 0, 'min_samples': 2, 'max_depth': 6}\n",
      "{'ml_task': 'classification', 'counter': 0, 'min_samples': 3, 'max_depth': 3}\n",
      "{'ml_task': 'classification', 'counter': 0, 'min_samples': 2, 'max_depth': 3}\n",
      "{'ml_task': 'classification', 'counter': 0, 'min_samples': 1, 'max_depth': 6}\n",
      "{'ml_task': 'classification', 'counter': 0, 'min_samples': 2, 'max_depth': 6}\n"
     ]
    }
   ],
   "source": [
    "rs.fit(train_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ml_task': 'classification', 'counter': 0, 'min_samples': 3, 'max_depth': 3}"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs.best_params_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
